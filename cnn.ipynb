{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GTZAN_genre_classification_key.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZfDOqYceIJnz",
        "outputId": "b7721cc0-7342-4401-f03e-96da545e8c08"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: mirdata in /usr/local/lib/python3.7/dist-packages (0.3.6)\n",
            "Requirement already satisfied: librosa>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from mirdata) (0.8.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from mirdata) (1.4.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from mirdata) (3.13)\n",
            "Requirement already satisfied: jams in /usr/local/lib/python3.7/dist-packages (from mirdata) (0.3.4)\n",
            "Requirement already satisfied: h5py>=2.10.0 in /usr/local/lib/python3.7/dist-packages (from mirdata) (3.1.0)\n",
            "Requirement already satisfied: smart-open>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from mirdata) (5.2.1)\n",
            "Requirement already satisfied: chardet in /usr/local/lib/python3.7/dist-packages (from mirdata) (3.0.4)\n",
            "Requirement already satisfied: pretty-midi>=0.2.8 in /usr/local/lib/python3.7/dist-packages (from mirdata) (0.2.9)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from mirdata) (2.23.0)\n",
            "Requirement already satisfied: Deprecated>=1.2.13 in /usr/local/lib/python3.7/dist-packages (from mirdata) (1.2.13)\n",
            "Requirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.7/dist-packages (from mirdata) (1.21.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from mirdata) (4.63.0)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.7/dist-packages (from Deprecated>=1.2.13->mirdata) (1.14.0)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.10.0->mirdata) (1.5.2)\n",
            "Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa>=0.8.0->mirdata) (2.1.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from librosa>=0.8.0->mirdata) (21.3)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.7/dist-packages (from librosa>=0.8.0->mirdata) (1.1.0)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.7/dist-packages (from librosa>=0.8.0->mirdata) (1.6.0)\n",
            "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from librosa>=0.8.0->mirdata) (1.0.2)\n",
            "Requirement already satisfied: numba>=0.43.0 in /usr/local/lib/python3.7/dist-packages (from librosa>=0.8.0->mirdata) (0.51.2)\n",
            "Requirement already satisfied: resampy>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from librosa>=0.8.0->mirdata) (0.2.2)\n",
            "Requirement already satisfied: soundfile>=0.10.2 in /usr/local/lib/python3.7/dist-packages (from librosa>=0.8.0->mirdata) (0.10.3.post1)\n",
            "Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa>=0.8.0->mirdata) (4.4.2)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.43.0->librosa>=0.8.0->mirdata) (0.34.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba>=0.43.0->librosa>=0.8.0->mirdata) (57.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->librosa>=0.8.0->mirdata) (3.0.7)\n",
            "Requirement already satisfied: appdirs>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa>=0.8.0->mirdata) (1.4.4)\n",
            "Requirement already satisfied: mido>=1.1.16 in /usr/local/lib/python3.7/dist-packages (from pretty-midi>=0.2.8->mirdata) (1.2.10)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from pretty-midi>=0.2.8->mirdata) (1.15.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->mirdata) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->mirdata) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->mirdata) (1.24.3)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn!=0.19.0,>=0.14.0->librosa>=0.8.0->mirdata) (3.1.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.7/dist-packages (from soundfile>=0.10.2->librosa>=0.8.0->mirdata) (1.15.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.0->soundfile>=0.10.2->librosa>=0.8.0->mirdata) (2.21)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from jams->mirdata) (1.3.5)\n",
            "Requirement already satisfied: jsonschema>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from jams->mirdata) (4.3.3)\n",
            "Requirement already satisfied: sortedcontainers>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from jams->mirdata) (2.4.0)\n",
            "Requirement already satisfied: mir-eval>=0.5 in /usr/local/lib/python3.7/dist-packages (from jams->mirdata) (0.7)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=3.0.0->jams->mirdata) (21.4.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from jsonschema>=3.0.0->jams->mirdata) (4.11.3)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=3.0.0->jams->mirdata) (0.18.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from jsonschema>=3.0.0->jams->mirdata) (3.10.0.2)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=3.0.0->jams->mirdata) (5.4.0)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources>=1.4.0->jsonschema>=3.0.0->jams->mirdata) (3.7.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from mir-eval>=0.5->jams->mirdata) (0.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->jams->mirdata) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->jams->mirdata) (2018.9)\n"
          ]
        }
      ],
      "source": [
        "# In this notebook you will build a CNN and train it to classify 10 different \n",
        "# musical genres\n",
        "\n",
        "# Fot this, we will use the GTZAN dataset\n",
        "# see https://mirdata.readthedocs.io/en/latest/_modules/mirdata/datasets/gtzan_genre.html\n",
        "# see \"Musical genre classification of audio signals \" by G. Tzanetakis and P. Cook\n",
        "\n",
        "# Let's start by installing and loading mirdata\n",
        "!pip install mirdata\n",
        "\n",
        "import mirdata"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# mount your Google drive so that you only have to download the data only once\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# intialize the gtzan dataset\n",
        "gtzan = mirdata.initialize('gtzan_genre', data_home='/content/drive/MyDrive')\n",
        "\n",
        "# download it (only once)\n",
        "gtzan.download(partial_download=['all']) # comment out this line after you have downloaded the data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aKZDe3WDIWdU",
        "outputId": "5b4e3d8f-8350-42b1-d815-f536647f61cb"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: NumExpr defaulting to 2 threads.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The GTZAN dataset has 1000 30-second-long \"tracks\" across 10 different musical genres\n",
        "\n",
        "# There are 100 recordings for each genre.\n",
        "\n",
        "# Let's split these recordings into training (~85%), validation (~10%), and test (~5%) sets\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# get the 100 different \"track_ids\"\n",
        "all_tracks = gtzan.track_ids\n",
        "\n",
        "# randomly separate these different \"track_ids\" intro training, validation, and test sets\n",
        "\n",
        "Ntracks = len(all_tracks)\n",
        "\n",
        "track_idx = np.random.choice(Ntracks,Ntracks,replace=False)\n",
        "\n",
        "tr_tracks = [all_tracks[i] for i in track_idx[:850]]\n",
        "vl_tracks = [all_tracks[i] for i in track_idx[850:950]]\n",
        "ts_tracks = [all_tracks[i] for i in track_idx[-50:]]"
      ],
      "metadata": {
        "id": "b-SpXaCeIn1Z"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# To feed this data into a CNN, we must define a DataGenerator class that\n",
        "# will create sequences of data and store them in mini batches\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import librosa\n",
        "\n",
        "class DataGenerator(tf.keras.utils.Sequence):\n",
        "    \n",
        "    # The class constructor\n",
        "    def __init__(\n",
        "          self, \n",
        "          track_ids,      # a list with the track_ids that belong to the set\n",
        "          batch_size=32,  # the default number of datapoints in a minibatch\n",
        "          ntime=None,     # to work with a time-frequency representation (you can work in another domain or with other features if you want)\n",
        "          nfft=None,      # to work with a time-frequency representation (you can work in another domain or with other features if you want)\n",
        "          n_channels=1,   # the default number of \"channels\" in the input to the CNN\n",
        "          n_classes=10,   # the number of classes          \n",
        "        ):\n",
        "            \n",
        "        self.ntime = ntime # to work with a time-frequency representation (you can work in another domain or with other features if you want)\n",
        "        self.nfft = nfft   # to work with a time-frequency representation (you can work in another domain or with other features if you want)\n",
        "        self.batch_size = batch_size        \n",
        "        self.track_ids = track_ids\n",
        "        self.n_channels = n_channels\n",
        "        self.n_classes = n_classes                \n",
        "\n",
        "    # this method returns how many batches there will be per epoch\n",
        "    def __len__(self):\n",
        "        '''\n",
        "        divide the total number of datapoints in the set\n",
        "        by the batch size. Make sure this returns an integer\n",
        "        '''\n",
        "        return int(np.floor(len(self.track_ids) / self.batch_size))\n",
        "\n",
        "    # iterates over the mini-batches by their index,\n",
        "    # generates them, and returns them\n",
        "    def __getitem__(self, index):\n",
        "        \n",
        "        # get the track ids that will be in a batch\n",
        "        track_ids_batch = self.track_ids[index*self.batch_size:(index+1)*self.batch_size]\n",
        "\n",
        "        # Generate data\n",
        "        X, y = self.__data_generation(track_ids_batch)\n",
        "\n",
        "        return X, y\n",
        "  \n",
        "    # actually loads the audio files and stores them in an array \n",
        "    def __data_generation(self, track_ids_batch):\n",
        "        ''''\n",
        "        the matrix with the audio data will have a shape [batch_size, ntime, nmel, n_channels] \n",
        "        (to work with a time-frequency representation; you can work in another domain if you want)\n",
        "        '''\n",
        "        \n",
        "        # Generate data\n",
        "        X = []\n",
        "        y = []\n",
        "        for t in track_ids_batch:\n",
        "            \n",
        "            # load the file\n",
        "            x, sr = gtzan.track(t).audio\n",
        "\n",
        "            # calculate the stft (to work with a time-frequency representation; you can work in another domain if you want)\n",
        "            # hint: do you really need to listen 30 seconds of audio to know the genre or a popular song?\n",
        "            x = librosa.stft(x, n_fft = self.nfft, hop_length=len(x)//(self.ntime-1)).T\n",
        "            \n",
        "            # convert to db (to work with a time-frequency representation; you can work in another domain if you want)\n",
        "            X.append(librosa.amplitude_to_db(np.abs(x))[...,np.newaxis])\n",
        "\n",
        "            # Store class index\n",
        "            if 'blues' in t:\n",
        "              y.append(0)\n",
        "            elif 'classical' in t:\n",
        "              y.append(1)\n",
        "            elif 'country' in t:\n",
        "              y.append(2)\n",
        "            elif 'disco' in t:\n",
        "              y.append(3)\n",
        "            elif 'hiphop' in t:\n",
        "              y.append(4)\n",
        "            elif 'jazz' in t:\n",
        "              y.append(5)\n",
        "            elif 'metal' in t:\n",
        "              y.append(6)\n",
        "            elif 'pop' in t:\n",
        "              y.append(7)\n",
        "            elif 'reggae' in t:\n",
        "              y.append(8)\n",
        "            elif 'rock' in t:\n",
        "              y.append(9)\n",
        "            else:\n",
        "              raise ValueError('label does not belong to valid category')\n",
        "\n",
        "        return np.array(X), tf.keras.utils.to_categorical(np.array(y), num_classes=self.n_classes)"
      ],
      "metadata": {
        "id": "fEL94VdNSxJ-"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# a very simple (and bad) CNN\n",
        "# you should make it better. This one is actually very very VERY bad\n",
        "\n",
        "# learning parameters\n",
        "lr = 0.0001\n",
        "\n",
        "# input data and label parameters\n",
        "ntime = 120\n",
        "nfft = 256\n",
        "nclasses = 10\n",
        "\n",
        "# declaring the input to the model\n",
        "inputs = tf.keras.Input(shape = (ntime,1+nfft//2,1))\n",
        "\n",
        "# defining the CNN\n",
        "cnn1 = tf.keras.layers.Conv2D(4, 5, activation = 'relu', padding='SAME')(inputs)\n",
        "mxp1 = tf.keras.layers.MaxPooling2D(pool_size = 2, strides = 2, padding='SAME')(cnn1)\n",
        "flat = tf.keras.layers.Flatten()(mxp1)\n",
        "outputs = tf.keras.layers.Dense(10)(flat)\n",
        "\n",
        "bad_cnn = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "# visualize the architecture\n",
        "bad_cnn.summary()\n",
        "\n",
        "# compile the model\n",
        "bad_cnn.compile(\n",
        "    loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=lr),\n",
        "    metrics=[\"accuracy\"],\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UpHmc-siUHpR",
        "outputId": "70c6fcd3-3b59-43d7-cf54-865ccbe21e4f"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_14\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_15 (InputLayer)       [(None, 120, 129, 1)]     0         \n",
            "                                                                 \n",
            " conv2d_14 (Conv2D)          (None, 120, 129, 4)       104       \n",
            "                                                                 \n",
            " max_pooling2d_14 (MaxPoolin  (None, 60, 65, 4)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_14 (Flatten)        (None, 15600)             0         \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, 10)                156010    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 156,114\n",
            "Trainable params: 156,114\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# define the data generators\n",
        "training_generator = DataGenerator(tr_tracks, ntime=ntime, nfft=nfft)\n",
        "validation_generator = DataGenerator(vl_tracks, ntime=ntime, nfft=nfft)"
      ],
      "metadata": {
        "id": "07hq2M9nUkQI"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train the model\n",
        "tr_logs = bad_cnn.fit(training_generator, validation_data=validation_generator, epochs=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wqBxGm63WKub",
        "outputId": "a55d9b62-c97f-49e7-8c11-2b6bc63220b4"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "26/26 [==============================] - 7s 246ms/step - loss: 10.8145 - accuracy: 0.1623 - val_loss: 7.8753 - val_accuracy: 0.2500\n",
            "Epoch 2/10\n",
            "26/26 [==============================] - 6s 238ms/step - loss: 5.8176 - accuracy: 0.2921 - val_loss: 5.9334 - val_accuracy: 0.3021\n",
            "Epoch 3/10\n",
            "26/26 [==============================] - 6s 238ms/step - loss: 4.8636 - accuracy: 0.3558 - val_loss: 6.2665 - val_accuracy: 0.2396\n",
            "Epoch 4/10\n",
            "26/26 [==============================] - 6s 239ms/step - loss: 3.4168 - accuracy: 0.4219 - val_loss: 5.2481 - val_accuracy: 0.2604\n",
            "Epoch 5/10\n",
            "26/26 [==============================] - 6s 238ms/step - loss: 3.1356 - accuracy: 0.4832 - val_loss: 4.9481 - val_accuracy: 0.2917\n",
            "Epoch 6/10\n",
            "26/26 [==============================] - 6s 236ms/step - loss: 2.0592 - accuracy: 0.5685 - val_loss: 4.6870 - val_accuracy: 0.3229\n",
            "Epoch 7/10\n",
            "26/26 [==============================] - 6s 239ms/step - loss: 1.6679 - accuracy: 0.6382 - val_loss: 4.9543 - val_accuracy: 0.3021\n",
            "Epoch 8/10\n",
            "26/26 [==============================] - 6s 240ms/step - loss: 1.3887 - accuracy: 0.6587 - val_loss: 4.6032 - val_accuracy: 0.3021\n",
            "Epoch 9/10\n",
            "26/26 [==============================] - 6s 238ms/step - loss: 1.1421 - accuracy: 0.7091 - val_loss: 4.7506 - val_accuracy: 0.3229\n",
            "Epoch 10/10\n",
            "26/26 [==============================] - 6s 237ms/step - loss: 0.6033 - accuracy: 0.8197 - val_loss: 4.4697 - val_accuracy: 0.3333\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f651661ddd0>"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# after training a good CNN, do the usual visualization of the training and validation loss across epochs\n",
        "\n",
        "# then inspect the model's accuracy on the validation set and the confusion matrix on the validation set\n",
        "\n",
        "# If you do everything right and design a good CNN, you should be able to train a model that achieves\n",
        "# over 70% accuracy on the validation set\n",
        "\n",
        "# If you do everything perfectly and design an outstanding CNN, you will be able to train a model that achieves\n",
        "# 90% accuracy on the validation set.\n",
        "\n",
        "# When you are done, analize the model's performance on the test set, \n",
        "# and create a post on our subreddit sharing your model's test-set accuracy\n",
        "# and confusion matrix"
      ],
      "metadata": {
        "id": "1qa3LnIKqpyy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}