{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"xlUjaK-lrulV"},"outputs":[],"source":["### Notebook for Pytorch implementation of NN-based PCVD classifier using Keras\n","# Potentially use as script for live coding tutorial after students have done the Keras version\n","\n","# Main Goals:\n","# 1. Intro to pytorch via a direct comparison to keras\n","# 2. A lower-level look at some of the abstractions/decisions one doesn't see/make in Keras\n","# 3. Review of the vowel classification problem by applying the same principles via different code/implementation\n","# 4. more practice with FC-MLP architecture design (beyond single layer logreg/softmax)\n","\n","# We will work with the PCVD dataset\n","# go to this website and click on Download\n","# https://www.kaggle.com/sabermalek/pcvcspeech\n","\n","# Then put the main folder in the same directory as this .ipynb file and rename it PCVD\n","\n","# mount your Google drive\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","#modify your pathfile here\n","%cd /content/drive/MyDrive/path/to/pcvd/PCVD"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ln-PjIa1r9-d"},"outputs":[],"source":["# This cell loads and processes the data\n","# you do not have to do anything here\n","\n","# The libraries needed\n","import os\n","import scipy.io\n","from scipy.signal.windows import hann\n","import numpy as np\n","import librosa\n","\n","# list all the files that are part of the dataset\n","all_mats = [i for i in os.listdir('.') if 'mat' in i]\n","\n","# load the time-series data in each of the data files\n","# and store them in a numpy array\n","data = []\n","for mat in all_mats:\n","  d = scipy.io.loadmat(mat)['x']\n","  data.append(d)\n","data = np.concatenate(data,axis=1)\n","\n","# reshape the data so that we have a matrix where each\n","# row is a datapoint (i.e. a vowel-consonant utterance)\n","_,nreps,nvow,nsamps=data.shape\n","data = np.reshape(data,(nreps*nvow,nsamps),order='F')\n","\n","# window the data to reduce the number of samples\n","# and center the window around the vowel\n","data = data[:,5000:15000]*hann(10000)\n","\n","# finally, resample the data have a sampling\n","# rate of 16000\n","sr = 16000\n","X = []\n","for d in data:\n","  X.append(librosa.resample(d,48000,sr))\n","data = np.array(X)\n","\n","print(\"The shape of the data is\", data.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jQjz9b5wlWzc"},"outputs":[],"source":["# \"data\" has the same number of datapoints for each vowel\n","# In farsi, there are 6 vowels. Considering the number of\n","# datapoints in \"data\". How many points do you have per vowel?\n","\n","ndatapoints_per_vowel = 299\n","\n","# now, the first ndatapoints_per_vowel rows in \"data\" contain\n","# datapoints that correspond to the vowel \"a\". The next\n","# ndatapoints_per_vowel rows correspond to the vowel \"i\", etc.\n","\n","# we need to create a \"labels\" vector with the same number of rows\n","# as \"data\" containing class indices 0-5.  We will not use one-hot encoding this time, as the loss function\n","# we will use is optimized to received class indices.\n","\n","labels = np.repeat(range(6),ndatapoints_per_vowel)\n","print(\"the shape of labels is\",labels.shape)\n","\n","# now randomly select ~5% of rows in \"data\" to be the test set\n","# Hint: you can use the np.random.choice function (with replace=False) \n","# and use the first ~5% of its output to index out the test set\n","# the remaining datapoints will be the \"development\" set\n","\n","N = data.shape[0]\n","\n","all_idx = np.random.choice(N,N,replace=False)\n","\n","data_ts = data[all_idx[:int(0.05*N)]]\n","labels_ts = labels[all_idx[:int(0.05*N)]]\n","data_dv = data[all_idx[int(0.05*N):]]\n","labels_dv = labels[all_idx[int(0.05*N):]]\n","\n","print(\"\\nThe shape of the development data is \", data_dv.shape)\n","print(\"The shape of the development labels is \", labels_dv.shape)\n","print(\"The shape of the testing data is \", data_ts.shape)\n","print(\"The shape of the testing labels is \", labels_ts.shape)\n","\n","# now we randomly select ~15% of the development\n","# data to be your validation set, and the rest to be your training\n","# set. In this homework we will NOT do k-fold cross-validation.\n","\n","N_dv = data_dv.shape[0]\n","\n","all_idx = np.random.choice(N_dv,N_dv,replace=False)\n","\n","Xvl = data_dv[all_idx[:int(0.15*N_dv)]]\n","Yvl = labels_dv[all_idx[:int(0.15*N_dv)]]\n","Xtr = data_dv[all_idx[int(0.15*N_dv):]]\n","Ytr = labels_dv[all_idx[int(0.15*N_dv):]]\n","\n","print(\"\\nThe shape of the training data is \", Xtr.shape)\n","print(\"The shape of the training labels is \", Ytr.shape)\n","print(\"The shape of the validation data is \", Xvl.shape)\n","print(\"The shape of the validation labels is \", Yvl.shape)\n","\n","# now we have to standardize the data.\n","\n","# Here each datapoint is a time-series. Additionally, we have\n","# a very limited number of datapoints. As a result, we must\n","# standardize each datapoint separately. Fortunately, audio time-series\n","# can be normalized to have zero mean and values that in the\n","# range between -1 and 1.\n","\n","# standardize the training and validation data so that each datapoint\n","# has a mean centered around zero, and the largest magnitude in a datapoint is 1\n","\n","mu_tr = np.mean(Xtr, axis=1, keepdims=True)\n","max_tr = np.max(np.abs(Xtr-mu_tr),axis=1, keepdims=True)\n","mu_vl = np.mean(Xvl, axis=1, keepdims=True)\n","max_vl = np.max(np.abs(Xvl-mu_vl),axis=1, keepdims=True)\n","\n","Xtr = (Xtr-mu_tr)/max_tr\n","Xvl = (Xvl-mu_vl)/max_vl"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MQQMRymv-NUh"},"outputs":[],"source":["# we have a very limited number of training data. \n","# as a result, we must \"augment\" the number of training datapoints\n","# here we suggest that you augment the data by adding noise to it\n","# and randomly shift its pitch. However, you should consider augmenting\n","# your data with even more techniques. \n","\n","# create a copy of your training data to add gaussian noise \n","# with a small variance\n","Xnoise = Xtr + 0.01*np.random.randn(*Xtr.shape)\n","\n","# create a copy of your training data to randomly shift \n","# the pitch of each datapoint by a few semitones\n","pitch_factors = np.random.uniform(-4,4,Xtr.shape[0])\n","Xpitch = []\n","for i, x in enumerate(Xtr):\n","  Xpitch.append(librosa.effects.pitch_shift(x,sr,pitch_factors[i]))\n","\n","# now concatenate your original data with the augmented datapoints\n","Xtr = np.concatenate((Xtr,Xnoise,np.array(Xpitch)),axis=0)\n","Ytr = np.concatenate((Ytr,Ytr,Ytr),axis=0)\n","\n","print(\"The shape of the training data is \", Xtr.shape)\n","print(\"The shape of the training labels is \", Ytr.shape)\n","print(\"The shape of the validation data is \", Xvl.shape)\n","print(\"The shape of the validation labels is \", Yvl.shape)"]},{"cell_type":"code","source":["# Now we will import pytorch and we will use this library\n","# to build our model\n","\n","# import necessary libraries\n","\n","# set the hardware device you will be training on\n","\n","#convert training data to Torch tensors on the current device:\n"],"metadata":{"id":"5wNUrpMEk5z9"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"joAcVn3mzbhn"},"outputs":[],"source":["# let's first define some training parameters:\n"]},{"cell_type":"code","source":["# Pytorch differs from Keras in that we define our computational graph (i.e. neural network) through a class that contains two main methods:\n","# 1) Initialization of the graph structure and parameters\n","# 2) Specification of the forward data flow through the graph\n","\n","# see https://pytorch.org/docs/stable/generated/torch.nn.Linear.html\n","# and https://pytorch.org/docs/stable/generated/torch.nn.Module.html\n","\n","# Next, we will set up the training optimization using the parameters we chose above:\n","\n","\n","# Then we define the loss function outside of the model class and before the training loop.\n","\n","# Next, we will create a function to compare the predicted classes and the actual classes to calculate the accuracy\n","\n","\n","############## Model Information #####################################\n","# Lastly we will print out the summary of our model:\n","# 1) The model structure\n","# 2) The name and size of each layer's weights + biases\n","# 3) The total number of trainable parameters (How do we know if a parameter is trainable?)\n","# Uncomment the following comment block when you have finished coding the above steps\n","'''\n","print(f\"Model structure: {model}\\n\")\n","for name, param in model.named_parameters():\n","    print(f\"Layer: {name} | Size: {param.size()}\")\n","\n","# total parameters and trainable parameters\n","total_params = sum(p.numel() for p in model.parameters())\n","print(f\"\\n{total_params:,} total parameters.\")\n","total_trainable_params = sum(\n","    p.numel() for p in model.parameters() if p.requires_grad)\n","print(f\"{total_trainable_params:,} training parameters.\\n\")\n","'''"],"metadata":{"id":"8JRofT7I1bZK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# now that the model has been built, let's see how it performs on the training\n","# data before being trained."],"metadata":{"id":"ToG4nAV5neCA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# now we can move on to train the model\n","\n","# When using standard pytorch, we must define training loops similar to those we used for our softmax classification training algorithm.\n","# We define an outer loop that will iterate through epochs\n","# Within each epoch, we will:\n","#   1. pass the (training/validation) data through the model to get predicted outputs\n","#   2. calculate the loss\n","#   3. backpropogate the gradient\n","#   4. test the model on the validation set\n","#   5. calculate the epoch statistics we care about\n","\n","# define 2 dictionaries which will store the accuracy/epoch and loss/epoch for both train and validation sets\n","\n","############## Main Training Loop ###################\n","# implement main training loop here"],"metadata":{"id":"PnimCgxTnH6Y"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xmdKc48qaGtV"},"outputs":[],"source":["# now that trianing is done, let's visualize the training and validation loss\n","# all of that information is readily available in the \"training logs\"\n","\n","import matplotlib.pyplot as plt\n","\n","# summarize history for loss"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"w1AnjPr9yRvS"},"outputs":[],"source":["# PERFORMANCE: validation set\n","\n","# let's see our model's confusion matrix with the validation set\n","\n","# calculate theta using the best parameters found\n","\n","# compute the confusion matrix and plot it\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RllrZbafNNmI"},"outputs":[],"source":["# now let's \"hear\" the model weights\n","\n","# to extract your model's weights, you will have to use your models layers' names,\n","# to access the the weights. You can use the .weight and .bias variables to get the actual data\n","\n","from IPython.display import Audio\n","Audio(data=W[5,:], rate=sr)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Z5IOgX7e1pVH"},"outputs":[],"source":["# Now let's see how the model does with the test data\n","\n","# Standardize your data. \n","mu_ts = np.mean(data_ts, axis=1, keepdims=True)\n","max_ts = np.max(np.abs(data_ts-mu_ts),axis=1, keepdims=True)\n","\n","Xts = (data_ts-mu_ts)/max_ts\n","\n","# Convert the test set to Torch tensors and put them on the appropriate device.\n","\n","# pass the test data through the model in evaluation mode and calculate the accuracy\n","\n","# compute the confusion matrix and plot it\n"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"nn_pytorch_base.ipynb","provenance":[{"file_id":"1rWT3z07RQCttgpzWVqj5fZwoiD10A6OZ","timestamp":1659664909834}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}