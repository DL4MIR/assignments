{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"softmax.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"xlUjaK-lrulV"},"outputs":[],"source":["# In this notebook we will optimize a softmax classifier\n","\n","# We will work with the PCVD dataset\n","\n","# go to this website and click on Download\n","# https://www.kaggle.com/sabermalek/pcvcspeech\n","\n","# Then put the files in the same directory as this .ipynb file\n","\n","# mount your Google drive\n","from google.colab import drive\n","drive.mount('/content/drive')\n","%cd /content/drive/MyDrive/your/path/to/PCVD #modify this path after MyDrive/"]},{"cell_type":"code","source":["# This cell loads and processes the data\n","# you do not have to do anything here\n","\n","# The libraries needed\n","import os\n","import scipy.io\n","from scipy.signal.windows import hann\n","import numpy as np\n","import librosa\n","\n","# list all the files that are part of the dataset\n","all_mats = [i for i in os.listdir('.') if 'mat' in i]\n","\n","# load the time-series data in each of the data files\n","# and store them in a numpy array\n","data = []\n","for mat in all_mats:\n","  d = scipy.io.loadmat(mat)['x']\n","  data.append(d)\n","data = np.concatenate(data,axis=1)\n","\n","# reshape the data so that we have a matrix where each\n","# row is a datapoint (i.e. a vowel-consonant utterance)\n","_,nreps,nvow,nsamps=data.shape\n","data = np.reshape(data,(nreps*nvow,nsamps),order='F')\n","\n","# window the data to reduce the number of samples\n","# and center the window around the vowel\n","data = data[:,5000:15000]*hann(10000)\n","\n","# finally, resample the data have a sampling\n","# rate of 16000\n","sr = 16000\n","X = []\n","for d in data:\n","  X.append(librosa.resample(d,48000,sr))\n","data = np.array(X)\n","\n","print(\"The shape of the data is\", data.shape)"],"metadata":{"id":"Ln-PjIa1r9-d"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# now listen a few example datapoints\n","# remember, each row of \"data\" is a datapoint\n","from IPython.display import Audio\n","Audio(data=data[0,:], rate=sr)"],"metadata":{"id":"kfEqJk10s3Bk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# \"data\" has the same number of datapoints for each vowel\n","# In farsi, there are 6 vowels. Considering the number of\n","# datapoints in \"data\". How many points do you have per vowel?\n","\n","ndatapoints_per_vowel = # ?\n","\n","# now, the first ndatapoints_per_vowel rows in \"data\" contain\n","# datapoints tha correspond to the vowel \"a\". The next\n","# ndatapoints_per_vowel rows correspond to the vowel \"i\", etc.\n","\n","# we need to create a \"labels\" matrix with the same number of rows\n","# as \"data\", and six columns. In \"labels\", each row has a 1 and\n","# the rest entries are zeros. The location of the number 1\n","# indicates which vowel the corresponding row of \"data\" has \n","# time-series data for\n","\n","labels = # your code here\n","\n","print(\"the shape of labels is\",labels.shape)"],"metadata":{"id":"jQjz9b5wlWzc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# now randomly select ~5% of rows in \"data\" to be the test set\n","# Hint: you can use the np.random.choice function (with replace=False) \n","# and use the first ~5% of its output to index out the test set\n","# the remaining datapoints will be the \"development\" set\n","\n","all_idx = np.random.choice(# your code here\n","\n","data_ts = # your code here\n","labels_ts = # your code here\n","data_dv = # your code here\n","labels_dv = # your code here\n","\n","print(\"The shape of the development data is \", data_dv.shape)\n","print(\"The shape of the development labels is \", labels_dv.shape)\n","print(\"The shape of the testing data is \", data_ts.shape)\n","print(\"The shape of the testing labels is \", labels_ts.shape)"],"metadata":{"id":"hs4LD_RWvpqY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# now we randomly select ~15% of the development\n","# data to be your validation set, and the rest to be your training\n","# set. In this homework we will NOT do k-fold cross-validation.\n","\n","# Q: why are we using only one fold as the validation set? Why are we not doing k-folds?\n","# A:\n","\n","all_idx = np.random.choice(# your code here\n","\n","Xvl = # your code here\n","Yvl = # your code here\n","Xtr = # your code here\n","Ytr = # your code here\n","\n","print(\"The shape of the training data is \", Xtr.shape)\n","print(\"The shape of the training labels is \", Ytr.shape)\n","print(\"The shape of the validation data is \", Xvl.shape)\n","print(\"The shape of the validation labels is \", Yvl.shape)"],"metadata":{"id":"IxZ_Voc58iMi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# now we have to standardize the data.\n","\n","# Here each datapoint is a time-series. Additionally, we have\n","# a very limited number of datapoints. As a result, we must\n","# standardize each datapoint separately. Fortunately, audio time-series\n","# can be normalized to have zero mean and values that in the\n","# range of values between -1 and 1.\n","\n","# standardize the training and validation data so that each datapoint\n","# has a mean centered around zero, and the largest value magnitude in a datapoint is 1\n","\n","mu_tr = # your code here\n","max_tr = # your code here\n","mu_vl = # your code here\n","max_vl = # your code here\n","\n","Xtr = (Xtr-mu_tr)/max_tr\n","Xvl = (Xvl-mu_vl)/max_vl"],"metadata":{"id":"XDLiLxje-5UE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# we have a very limited number of training data. \n","# as a result, we must \"augment\" the number of training datapoints\n","# here we suggest that you augment the data by adding noise to it\n","# and randomly shift its pitch. However, you should consider augmenting\n","# your data with even more techniques. \n","\n","# Q: why should we augment our data?\n","# A:\n","\n","# create a copy of your training data to add gaussian noise \n","# with a small variance\n","Xnoise = Xtr + # your code here\n","\n","# create a copy of your training data to randomly shift \n","# the pitch of each datapoint by a few semitones\n","pitch_factors = # your code here\n","Xpitch = []\n","for i, x in enumerate(Xtr):\n","  Xpitch.append(librosa.effects.pitch_shift(# your code here\n","\n","# now concatenate your original data with the augmented datapoints\n","Xtr = np.concatenate((Xtr,Xnoise,np.array(Xpitch)),axis=0)\n","Ytr = np.concatenate((Ytr,Ytr,Ytr),axis=0)\n","\n","print(\"The shape of the training data is \", Xtr.shape)\n","print(\"The shape of the training labels is \", Ytr.shape)\n","print(\"The shape of the validation data is \", Xvl.shape)\n","print(\"The shape of the validation labels is \", Yvl.shape)\n","\n","# you should consider applying more data augmentation in order\n","# to be able to train a more robust model. However, not all\n","# data augmentation for audio will be good given what we are trying to do here\n","\n","# CAUTION: Running this cell more than once can result in your number of\n","# training datapoints growing expontentially, but being very redundant"],"metadata":{"id":"MQQMRymv-NUh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# use this cell to hear the differences between your\n","# original training data and its \"augmented\" versions\n","from IPython.display import Audio\n","Audio(data=Xtr, rate=sr)"],"metadata":{"id":"NUp2gLKLC9J0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Here's the main body of this homework\n","\n","# we will use for loops to explore the hyperparameter space\n","# and find the best training routine for our softmax classifier. \n","\n","# Here is a hint: the number of epochs used to obtain the\n","# baseline model was 5000. To beat the baseline model you may \n","# have to train for more (or maybe you can do less) epochs.\n","epochs = 5000\n","\n","# define a list with regularization values that you want to try\n","regs = # your code here\n","# define a list with learning rates that you want to try\n","lrs = # your code here\n","\n","# for each combination of reg+lr values, we will save\n","# the best parameters, weights, and cost functions\n","results = []\n","for reg in regs:\n","  for lr in lrs:\n","    \n","    print(\"\\n####################################\\n\")\n","\n","    # intialize the model parameters that we want \n","    # to learn using the training data\n","    W = # your code here\n","    b = # your code here\n","\n","    # initialize the \"best validation cost function\" to be \"infinity\"\n","    best_Jvl = float(\"inf\")\n","    # initialize the \"best\" W and the \"best\" b\n","    best_W = np.array(W)\n","    best_b = np.array(b)\n","\n","    # initialize a list to save all the\n","    # training and validation cost at each epoch\n","    all_Jtr = []\n","    all_Jvl = []\n","        \n","    # now show the training data \n","    # to the model and optimize\n","    # via gradient descent\n","    for e in range(epochs):\n","\n","      # calculate y_hat with the training data\n","      # Q: what do you expect the initial average y_hat_tr (training) to be? why?\n","      # A:   \n","      y_hat_tr = # your code here\n","      \n","      # calculate y_hat with the validation data\n","      y_hat_vl = # your code here\n","      \n","      # calculate the cost function with the training data (do not forget to regularize W with L2)\n","      # Q: what do you expect the initial J with the training data to be? why?\n","      # A:   \n","      Jtr = # your code here\n","      all_Jtr.append(Jtr)\n","      # Q: why don't we regularize \"b\"?\n","      # A:\n","      \n","      # calculate the cost function with the validation data (regularizing W with L2)\n","      Jvl = # your code here\n","      all_Jvl.append(Jvl)\n","      \n","      # save the best validation cost\n","      if Jvl < best_Jvl:\n","        best_Jvl = Jvl\n","        best_W = np.array(W)\n","        best_b = np.array(b)\n","        \n","      # Let's print some progress indicators\n","      if e%500 == 0:\n","        print(\"epoch {} with reg {} and lr {}, Jtr = {}\".format(e,reg,lr,Jtr))\n","        print(\"           with reg {} and lr {}, Jvl = {}\".format(reg,lr,Jvl))      \n","      # Q: will Jtr and Jvl be the same, roughly the same, or always different?\n","      # A:\n","      # Q: what relationship do you expect to see between Jtr and Jvl?\n","      # A:\n","      # Q: how will you know if you model is overfitting to the training data?\n","      # A:      \n","\n","      # now find the gradient of the parameters\n","      # that we want to optimize. Do not forget the L2 regularization applied to W\n","      dw = # your code here\n","      db = # your code here\n","      # Q: why do we need to apply regularization to W?\n","      # A:\n","      # Q: what effect does regularization have on the cost function?\n","      # A:\n","      # Q: why do we not apply regularization to b?\n","\n","      # update the model parameters\n","      W -= lr*dw.T\n","      b -= lr*db\n","    \n","    # after the epochs are over, save the training and validation losses, \n","    # as well as the best_W and best_b parameters you found\n","    results.append([lr, reg, best_Jvl, all_Jtr, all_Jvl, best_W, best_b])"],"metadata":{"id":"joAcVn3mzbhn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# PERFORMANCE: validation set\n","\n","# now that training is over, let's see how the parameters we found\n","# for each combination of regularization and learning rate perform \n","# on the VALIDATION set\n","import matplotlib.pyplot as plt\n","import sklearn\n","\n","for p in results:\n","\n","  # unpack the variables needed to compute the results\n","  lr, reg, best_Jvl, all_Jtr, all_Jvl, best_W, best_b = p\n","\n","  print(\"\\n\\n\\nWith a learning rate of {} and a regularization of {}\\n\".format(lr, reg))  \n","  \n","  # let's plot the loss over epochs\n","  plt.plot(all_Jtr,label='Jtr')\n","  plt.plot(all_Jvl,label='Jvl')  \n","  plt.xlabel('epoch')\n","  plt.legend()\n","  plt.show()\n","\n","  # calculate y_hat_vl using the best parameters found\n","  y_hat_vl = # your code here\n","  \n","  # calculate the model accuracy\n","  acc = # your code here\n","  print(\"The accuracy was\", acc)\n","  \n","  # compute the confusion matrix and plot it\n","  conf_mat = sklearn.metrics.confusion_matrix(# your code here\n","  disp = sklearn.metrics.ConfusionMatrixDisplay(confusion_matrix=conf_mat,display_labels=[\"a\",\"i\",\"u\",\"ae\",\"e\",\"o\"])\n","  disp.plot()\n","  plt.show()\n","\n","# to beat the \"baseline\" model, you will have to do\n","# several types of data augmentation and thoroughly explore\n","# the hyperparameter space (i.e. combinations of regularization and learning rate)"],"metadata":{"id":"w1AnjPr9yRvS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Here's something kinda cool. Since each column of W helps separating\n","# a different vowel, after training W, you can \"hear the vowels\" in the \n","# columns of the best weights you got.\n","Audio(data=results[0][5][:,0], rate=sr) # you will have to index results properly to access the best_W you found"],"metadata":{"id":"RllrZbafNNmI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# when you are done optimizing your absolue best model, carry out the same performance\n","# evaluation with the test set. Do not forget to standardize your data. \n","# When you are done, submit a picture of your final evaluation as a post to our Discord channel\n","# https://discord.com/channels/997586458116366397/997586458716147734\n","\n","# post the accuracy and the confusion matrix on the evaluation set\n","\n","mu_ts = # your code here\n","max_ts = # your code here\n","\n","Xts = (data_ts-mu_ts)/max_ts\n","\n","# unpack the parameters that gave you the best results\n","lr, reg, best_Jvl, all_Jtr, all_Jvl, best_W, best_b = # your code here\n","\n","print(\"\\n\\n\\nWith a learning rate of {} and a regularization of {}\\n\".format(lr, reg))  \n","\n","# let's plot the loss over epochs\n","plt.plot(all_Jtr,label='Jtr')\n","plt.plot(all_Jvl,label='Jvl')  \n","plt.xlabel('epoch')\n","plt.legend()\n","plt.show()\n","\n","# calculate y_hat_vl using the best parameters found\n","y_hat_ts = # your code here\n","\n","# calculate the model accuracy\n","acc = # your code here\n","print(\"The test-set accuracy was\", acc)\n","\n","# compute the confusion matrix and plot it\n","conf_mat = sklearn.metrics.confusion_matrix(# your code here\n","disp = sklearn.metrics.ConfusionMatrixDisplay(confusion_matrix=conf_mat,display_labels=[\"a\",\"i\",\"u\",\"ae\",\"e\",\"o\"])\n","disp.plot()\n","plt.show()\n"],"metadata":{"id":"Z5IOgX7e1pVH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# you are done with the homework. The next cell lets you record 2 seconds of\n","# audio. Then you can use your model to infer the vowel you said in the audio recording."],"metadata":{"id":"RFGeS3OLrKdG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@markdown Either record audio from microphone or upload audio from file (.mp3 or .wav) { run: \"auto\" }\n","\n","# imports for uploading/recording\n","%cd ~\n","!pip install pydub\n","!git clone -q --depth 1 https://github.com/snakers4/silero-models\n","%cd silero-models\n","import numpy as np\n","import ipywidgets as widgets\n","from scipy.io import wavfile\n","from IPython.display import Audio, display, clear_output\n","from colab_utils import (record_audio,\n","                         audio_bytes_to_np,\n","                         upload_audio)\n","\n","record_or_upload = \"Record\" #@param [\"Record\", \"Upload (.mp3 or .wav)\"]\n","record_seconds =   2#@param {type:\"number\", min:1, max:10, step:1}\n","sample_rate = 16000\n","  \n","def _record_audio(b):\n","  clear_output()\n","  audio = record_audio(record_seconds)\n","  wavfile.write('recorded.wav', sample_rate, (32767*audio).numpy().astype(np.int32))  \n","\n","def _upload_audio(b):\n","  clear_output()\n","  audio = upload_audio()  \n","  return audio\n","\n","if record_or_upload == \"Record\":\n","  button = widgets.Button(description=\"Record Speech\")\n","  button.on_click(_record_audio)\n","  display(button)\n","else:\n","  audio = _upload_audio(\"\")"],"metadata":{"cellView":"form","id":"10xDqwXWd8Ad"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# this cell is very \"hacky\" and assumes that you were constantly\n","# saying a vowel for the duration of a two second recording\n","\n","# load the audio\n","audio, sr = librosa.load('recorded.wav',sr=sr)\n","\n","# window to match the audio length that we trained the model to recognize\n","audio = audio[np.newaxis,sr//2:sr//2+3334]*hann(3334)\n","\n","# normalize the audio as we did before\n","mu_rec = # your code here\n","max_rec = # your code here\n","x = (audio-mu_rec)/max_rec\n","\n","# unpack the parameters that gave you the best results\n","lr, reg, best_Jvl, all_Jtr, all_Jvl, best_W, best_b = # your code here\n","\n","# carry out inference with your best parameters\n","y_hat_rec = # your code here\n","\n","# print results and hear the recording\n","vowels = ['a','i','u','ae','e','o']\n","print('You said the vowel ',vowels[np.argmax(y_hat_rec)])\n","Audio(data=x, rate=sr)"],"metadata":{"id":"DJ-s72q4gb2t"},"execution_count":null,"outputs":[]}]}