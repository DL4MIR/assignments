{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"GTZAN_genre_classification_KaggleDataset.ipynb","provenance":[{"file_id":"https://github.com/dl4genaudio/assignments/blob/main/cnn.ipynb","timestamp":1658968123934}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","execution_count":5,"metadata":{"id":"ZfDOqYceIJnz","executionInfo":{"status":"ok","timestamp":1659131271264,"user_tz":420,"elapsed":108,"user":{"displayName":"Camille Noufi","userId":"04628122647747040750"}}},"outputs":[],"source":["# In this notebook you will build a CNN and train it to classify 10 different \n","# musical genres\n","\n","# Fot this, we will use the GTZAN dataset hosted on Kaggle: https://www.kaggle.com/datasets/carlthome/gtzan-genre-collection\n","# see \"Musical genre classification of audio signals \" by G. Tzanetakis and P. Cook"]},{"cell_type":"code","source":["# mount your Google drive so that you only have to download the data only once\n","from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aKZDe3WDIWdU","outputId":"2a70229c-c1b0-4a55-aec1-3464a359d19e","executionInfo":{"status":"ok","timestamp":1659131273998,"user_tz":420,"elapsed":920,"user":{"displayName":"Camille Noufi","userId":"04628122647747040750"}}},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["# change the current working directory to be where this .ipynb is located within your Drive\n","# make sure you 'include the full folder path beginning with /content/gdrive/MyDrive'\n","%cd /content/drive/MyDrive/Teaching/DL4MIR2022/Notebooks"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eQaZ1k6Tqisk","executionInfo":{"status":"ok","timestamp":1659131276720,"user_tz":420,"elapsed":458,"user":{"displayName":"Camille Noufi","userId":"04628122647747040750"}},"outputId":"9c89c5e8-05cf-4fbb-ab73-6d81df509d92"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Teaching/DL4MIR2022/Notebooks\n"]}]},{"cell_type":"code","source":["# Now we will download the GTZAN dataset from Kaggle. To do this, use the following steps.\n","\n","# 1. Make a Kaggle account: https://www.kaggle.com/account/login?phase=startRegisterTab&returnUrl=%2F\n","# 2. Go to your account, scroll to the API section. Click Expire API Token to remove previous tokens if necessary.\n","# 3. Click on Create New API Token. It will download a kaggle.json file on your machine.\n","\n","# 4. Upload the file from your machine:\n","!pip install -q kaggle\n","from google.colab import files\n","files.upload()\n","\n","# 5. make a new directory within Drive named kaggle and copy the kaggle.json file there\n","!rm -r ~/.kaggle\n","!mkdir ~/.kaggle\n","!mv ./kaggle.json ~/.kaggle/\n","\n","# 6. change the permissions of the file\n","!chmod 600 ~/.kaggle/kaggle.json"],"metadata":{"colab":{"resources":{"http://localhost:8080/nbextensions/google.colab/files.js":{"data":"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","ok":true,"headers":[["content-type","application/javascript"]],"status":200,"status_text":""}},"base_uri":"https://localhost:8080/","height":74},"id":"cp9fg1GisQh4","executionInfo":{"status":"ok","timestamp":1659131291605,"user_tz":420,"elapsed":9897,"user":{"displayName":"Camille Noufi","userId":"04628122647747040750"}},"outputId":"67155a6d-7c45-4f44-dbac-f8b5e2404072"},"execution_count":8,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","     <input type=\"file\" id=\"files-33ed9fe2-8e2a-40f1-b79c-f35dac645f42\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-33ed9fe2-8e2a-40f1-b79c-f35dac645f42\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script src=\"/nbextensions/google.colab/files.js\"></script> "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Saving kaggle.json to kaggle.json\n"]}]},{"cell_type":"code","source":["# Now we are ready to download the GTZAN dataset.\n","# YOU ONLY NEED TO RUN THIS ONCE!\n","!kaggle datasets download -d carlthome/gtzan-genre-collection --unzip"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"95U6SMipuxJd","executionInfo":{"status":"ok","timestamp":1659130888621,"user_tz":420,"elapsed":578,"user":{"displayName":"Camille Noufi","userId":"04628122647747040750"}},"outputId":"f194b082-28be-457a-c36a-6f065f61ad4f"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Traceback (most recent call last):\n","  File \"/usr/local/bin/kaggle\", line 5, in <module>\n","    from kaggle.cli import main\n","  File \"/usr/local/lib/python3.7/dist-packages/kaggle/__init__.py\", line 23, in <module>\n","    api.authenticate()\n","  File \"/usr/local/lib/python3.7/dist-packages/kaggle/api/kaggle_api_extended.py\", line 166, in authenticate\n","    self.config_file, self.config_dir))\n","OSError: Could not find kaggle.json. Make sure it's located in /root/.kaggle. Or use the environment method.\n"]}]},{"cell_type":"code","source":["#9. Confirm the dataset is downloaded and unzipped in the expected location:\n","# you should see a the full 'genres' folder path and a list of all the genres in the dataset\n","%cd genres\n","!ls\n","%cd ..\n","\n","# 10. Pat yourself on the back! \n","# Kaggle is a great source for open-source and competition datasets.  You can use this process to work with other datasets"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0W0xBjtArxQZ","executionInfo":{"status":"ok","timestamp":1659131304348,"user_tz":420,"elapsed":543,"user":{"displayName":"Camille Noufi","userId":"04628122647747040750"}},"outputId":"56290af0-274c-4d61-8666-e618bb0d6a6f"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Teaching/DL4MIR2022/Notebooks/genres\n","blues  classical  country  disco  hiphop  jazz\tmetal  pop  reggae  rock\n","/content/drive/MyDrive/Teaching/DL4MIR2022/Notebooks\n"]}]},{"cell_type":"code","source":["# The GTZAN dataset has 1000 30-second-long \"tracks\" across 10 different musical genres\n","# There are 100 recordings for each genre.\n","\n","# Let's explore the format of the downloaded dataset.  We can look at the dataset on the Kaggle page to get an idea of the file structure:\n","#     https://www.kaggle.com/datasets/carlthome/gtzan-genre-collection\n","# The Data Explorer on the right-hand pane provides a graphical version of the file structure.\n","# We can see that each filename contains the genre and a unique number within that folder.  \n","# We can use these file names as our track ids.\n","\n","import os\n","import numpy as np\n","import librosa\n","\n","# get the 1000 different \"track_ids\" by recursing over directory and subidrectory\n","\n","def getTrackIDs(dir_name):\n","    # create a list of file and sub directories \n","    # names in the given directory \n","    file_list = os.listdir(dir_name)\n","    all_tracks = list()\n","    # Iterate over all the entries\n","    for entry in file_list:\n","        # Create full path\n","        full_path = os.path.join(dir_name, entry)\n","        # If entry is a directory then get the list of files in this directory \n","        if os.path.isdir(full_path):\n","            all_tracks = all_tracks + getTrackIDs(full_path)\n","        else:\n","            all_tracks.append(full_path)   \n","    return all_tracks\n","\n","all_tracks = getTrackIDs('./genres')\n","\n","print(\"Number of tracks: \", len(all_tracks))\n","\n","sample_id = all_tracks[len(all_tracks)-1]\n","print(\"Sample track ID:\", sample_id)\n","\n","# Q: Why do we want to store the filepath rather than just the filename?\n","# A: \n","\n","# It is always good to explore your data files before you begin working with them. Let's check out the structure of one of the audio files:\n","x, sr = librosa.load(sample_id, sr=None)\n","\n","print('\\nSignal Shape:', x.shape)\n","print('Sampling Rate:', sr)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aT1sVvGHtg1C","executionInfo":{"status":"ok","timestamp":1659131331833,"user_tz":420,"elapsed":13672,"user":{"displayName":"Camille Noufi","userId":"04628122647747040750"}},"outputId":"12c9da8d-4e5e-4f34-b7d3-fa7dd7912abc"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/resampy/interpn.py:114: NumbaWarning: The TBB threading layer requires TBB version 2019.5 or later i.e., TBB_INTERFACE_VERSION >= 11005. Found TBB_INTERFACE_VERSION = 9107. The TBB threading layer is disabled.\n","  _resample_loop_p(x, t_out, interp_win, interp_delta, num_table, scale, y)\n"]},{"output_type":"stream","name":"stdout","text":["Number of tracks:  1000\n","Sample track ID: ./genres/rock/rock.00099.au\n","\n","Signal Shape: (661794,)\n","Sampling Rate: 22050\n"]}]},{"cell_type":"code","source":["# Let's split these recordings into training (~85%), validation (~10%), and test (~5%) sets\n","# randomly separate these different \"track_ids\" intro training, validation, and test sets\n","\n","Ntracks = len(all_tracks)\n","\n","track_idx = np.random.choice(Ntracks,Ntracks,replace=False)\n","\n","tr_tracks = [all_tracks[i] for i in track_idx[:850]]\n","vl_tracks = [all_tracks[i] for i in track_idx[850:950]]\n","ts_tracks = [all_tracks[i] for i in track_idx[-50:]]"],"metadata":{"id":"b-SpXaCeIn1Z","executionInfo":{"status":"ok","timestamp":1659131336055,"user_tz":420,"elapsed":104,"user":{"displayName":"Camille Noufi","userId":"04628122647747040750"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["# To feed this data into a CNN, we must define a DataGenerator class that\n","# will create sequences of data and store them in mini batches\n","\n","import tensorflow as tf\n","\n","class DataGenerator(tf.keras.utils.Sequence):\n","    \n","    # The class constructor\n","    def __init__(\n","          self, \n","          track_ids,      # a list with the track_ids that belong to the set\n","          batch_size=32,  # the default number of datapoints in a minibatch\n","          ntime=None,     # to work with a time-frequency representation (you can work in another domain or with other features if you want)\n","          nfft=None,      # to work with a time-frequency representation (you can work in another domain or with other features if you want)\n","          n_channels=1,   # the default number of \"channels\" in the input to the CNN\n","          n_classes=10,   # the number of classes          \n","        ):\n","            \n","        self.ntime = ntime # to work with a time-frequency representation (you can work in another domain or with other features if you want)\n","        self.nfft = nfft   # to work with a time-frequency representation (you can work in another domain or with other features if you want)\n","        self.batch_size = batch_size        \n","        self.track_ids = track_ids\n","        self.n_channels = n_channels\n","        self.n_classes = n_classes                \n","\n","    # this method returns how many batches there will be per epoch\n","    def __len__(self):\n","        '''\n","        divide the total number of datapoints in the set\n","        by the batch size. Make sure this returns an integer\n","        '''\n","        return int(np.floor(len(self.track_ids) / self.batch_size))\n","\n","    # iterates over the mini-batches by their index,\n","    # generates them, and returns them\n","    def __getitem__(self, index):\n","        \n","        # get the track ids that will be in a batch\n","        track_ids_batch = self.track_ids[index*self.batch_size:(index+1)*self.batch_size]\n","\n","        # Generate data\n","        X, y = self.__data_generation(track_ids_batch)\n","\n","        return X, y\n","  \n","    # actually loads the audio files and stores them in an array \n","    def __data_generation(self, track_ids_batch):\n","        ''''\n","        the matrix with the audio data will have a shape [batch_size, ntime, nmel, n_channels] \n","        (to work with a time-frequency representation; you can work in another domain if you want)\n","        '''\n","        \n","        # Generate data\n","        X = []\n","        y = []\n","        for t in track_ids_batch:\n","            \n","            # load the file\n","            x, sr = librosa.load(sample_id, sr=None)\n","            # calculate the stft (to work with a time-frequency representation; you can work in another domain if you want)\n","            # hint: do you really need to listen 30 seconds of audio to know the genre of a popular song?\n","            x = librosa.stft(x, n_fft = self.nfft, hop_length=len(x)//(self.ntime-1)).T\n","            \n","            # convert to db (to work with a time-frequency representation; you can work in another domain if you want)\n","            X.append(librosa.amplitude_to_db(np.abs(x))[...,np.newaxis])\n","\n","            # Store class index\n","            if 'blues' in t:\n","              y.append(0)\n","            elif 'classical' in t:\n","              y.append(1)\n","            elif 'country' in t:\n","              y.append(2)\n","            elif 'disco' in t:\n","              y.append(3)\n","            elif 'hiphop' in t:\n","              y.append(4)\n","            elif 'jazz' in t:\n","              y.append(5)\n","            elif 'metal' in t:\n","              y.append(6)\n","            elif 'pop' in t:\n","              y.append(7)\n","            elif 'reggae' in t:\n","              y.append(8)\n","            elif 'rock' in t:\n","              y.append(9)\n","            else:\n","              raise ValueError('label does not belong to valid category')\n","\n","        return np.array(X), tf.keras.utils.to_categorical(np.array(y), num_classes=self.n_classes)"],"metadata":{"id":"fEL94VdNSxJ-","executionInfo":{"status":"ok","timestamp":1659132926502,"user_tz":420,"elapsed":130,"user":{"displayName":"Camille Noufi","userId":"04628122647747040750"}}},"execution_count":38,"outputs":[]},{"cell_type":"code","source":["# a very simple (and bad) CNN\n","# you should make it better. This one is actually very very VERY bad\n","\n","# learning parameters\n","lr = 0.0001\n","\n","# input data and label parameters\n","ntime = 120\n","nfft = 256\n","nclasses = 10\n","\n","# declaring the input to the model\n","inputs = tf.keras.Input(shape = (ntime,1+nfft//2,1))\n","\n","# defining the CNN\n","cnn1 = tf.keras.layers.Conv2D(4, 5, activation = 'relu', padding='SAME')(inputs)\n","mxp1 = tf.keras.layers.MaxPooling2D(pool_size = 2, strides = 2, padding='SAME')(cnn1)\n","flat = tf.keras.layers.Flatten()(mxp1)\n","outputs = tf.keras.layers.Dense(10)(flat)\n","\n","bad_cnn = tf.keras.Model(inputs=inputs, outputs=outputs)\n","\n","# visualize the architecture\n","bad_cnn.summary()\n","\n","# compile the model\n","bad_cnn.compile(\n","    loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n","    optimizer=tf.keras.optimizers.Adam(learning_rate=lr),\n","    metrics=[\"accuracy\"],\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UpHmc-siUHpR","outputId":"0a08c4e7-544a-4ef7-9bad-165925001f46","executionInfo":{"status":"ok","timestamp":1659132928932,"user_tz":420,"elapsed":150,"user":{"displayName":"Camille Noufi","userId":"04628122647747040750"}}},"execution_count":39,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model_6\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_7 (InputLayer)        [(None, 120, 129, 1)]     0         \n","                                                                 \n"," conv2d_6 (Conv2D)           (None, 120, 129, 4)       104       \n","                                                                 \n"," max_pooling2d_6 (MaxPooling  (None, 60, 65, 4)        0         \n"," 2D)                                                             \n","                                                                 \n"," flatten_6 (Flatten)         (None, 15600)             0         \n","                                                                 \n"," dense_6 (Dense)             (None, 10)                156010    \n","                                                                 \n","=================================================================\n","Total params: 156,114\n","Trainable params: 156,114\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["# define the data generators\n","training_generator = DataGenerator(tr_tracks, ntime=ntime, nfft=nfft)\n","validation_generator = DataGenerator(vl_tracks, ntime=ntime, nfft=nfft)"],"metadata":{"id":"07hq2M9nUkQI","executionInfo":{"status":"ok","timestamp":1659132937469,"user_tz":420,"elapsed":125,"user":{"displayName":"Camille Noufi","userId":"04628122647747040750"}}},"execution_count":40,"outputs":[]},{"cell_type":"code","source":["# train the model\n","tr_logs = bad_cnn.fit(training_generator, validation_data=validation_generator, epochs=10)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wqBxGm63WKub","outputId":"d530a8a9-dc4b-4672-a240-e19753818024","executionInfo":{"status":"ok","timestamp":1659133003740,"user_tz":420,"elapsed":61145,"user":{"displayName":"Camille Noufi","userId":"04628122647747040750"}}},"execution_count":41,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","26/26 [==============================] - 7s 245ms/step - loss: 2.8688 - accuracy: 0.0938 - val_loss: 2.3112 - val_accuracy: 0.1042\n","Epoch 2/10\n","26/26 [==============================] - 6s 228ms/step - loss: 2.3882 - accuracy: 0.0998 - val_loss: 2.3563 - val_accuracy: 0.1458\n","Epoch 3/10\n","26/26 [==============================] - 6s 226ms/step - loss: 2.3534 - accuracy: 0.0974 - val_loss: 2.3314 - val_accuracy: 0.0833\n","Epoch 4/10\n","26/26 [==============================] - 6s 228ms/step - loss: 2.3488 - accuracy: 0.1058 - val_loss: 2.3249 - val_accuracy: 0.1458\n","Epoch 5/10\n","26/26 [==============================] - 7s 265ms/step - loss: 2.3616 - accuracy: 0.0974 - val_loss: 2.3468 - val_accuracy: 0.1146\n","Epoch 6/10\n","26/26 [==============================] - 6s 228ms/step - loss: 2.3569 - accuracy: 0.1022 - val_loss: 2.4425 - val_accuracy: 0.0521\n","Epoch 7/10\n","26/26 [==============================] - 6s 226ms/step - loss: 2.3770 - accuracy: 0.0877 - val_loss: 2.4065 - val_accuracy: 0.0729\n","Epoch 8/10\n","26/26 [==============================] - 6s 226ms/step - loss: 2.3504 - accuracy: 0.0950 - val_loss: 2.3336 - val_accuracy: 0.1458\n","Epoch 9/10\n","26/26 [==============================] - 6s 225ms/step - loss: 2.3778 - accuracy: 0.0950 - val_loss: 2.3272 - val_accuracy: 0.0938\n","Epoch 10/10\n","26/26 [==============================] - 6s 227ms/step - loss: 2.3675 - accuracy: 0.0805 - val_loss: 2.3373 - val_accuracy: 0.1042\n"]}]},{"cell_type":"code","source":["# after training a good CNN, do the usual visualization of the training and validation loss across epochs\n","\n","# then inspect the model's accuracy on the validation set and the confusion matrix on the validation set\n","\n","# If you do everything right and design a good CNN, you should be able to train a model that achieves\n","# over 70% accuracy on the validation set\n","\n","# If you do everything perfectly and design an outstanding CNN, you will be able to train a model that achieves\n","# 90% accuracy on the validation set.\n","\n","# When you are done, analize the model's performance on the test set, \n","# and create a post on our subreddit sharing your model's test-set accuracy\n","# and confusion matrix"],"metadata":{"id":"1qa3LnIKqpyy","executionInfo":{"status":"ok","timestamp":1659131490446,"user_tz":420,"elapsed":116,"user":{"displayName":"Camille Noufi","userId":"04628122647747040750"}}},"execution_count":17,"outputs":[]}]}